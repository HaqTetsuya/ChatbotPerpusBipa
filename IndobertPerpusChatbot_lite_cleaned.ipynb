{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaqTetsuya/ChatbotPerpusBipa/blob/main/IndobertPerpusChatbot_lite_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baq_vbCGocRh",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title download dependancy\n",
        "!pip install transformers torch pandas scikit-learn matplotlib seaborn tqdm deep-translator fuzzywuzzy Levenshtein\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8eolkt8hn4u",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title import dependency, load drive, and github {\"form-width\":\"20%\"}\n",
        "!git clone https://github.com/HaqTetsuya/ChatbotPerpusBipa.git\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "from google.colab import drive, files\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "#from tqdm import tqdm\n",
        "from tqdm.auto import tqdm  # If you need both tqdm and tqdm.auto\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "FName = \"models\" #@param {type:\"string\"}\n",
        "\n",
        "# Update MODEL_SAVE_PATH with user input\n",
        "MODEL_SAVE_PATH = f\"/content/drive/MyDrive/{FName}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Kelas Dataset untuk IndoBERT\n",
        "class IntentDataset(Dataset):\n",
        "    \"\"\"Dataset untuk klasifikasi intent dengan IndoBERT\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Convert dict of tensors to flat tensors\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(label)\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FWHhQIZ43RjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqQ8ahtVzC6r",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title load data\n",
        "\n",
        "def load_csv_data(csv_path, label_encoder=None, show_distribution=False):\n",
        "    \"\"\"Memuat data intent dari file CSV. Bisa untuk train/test tanpa split.\"\"\"\n",
        "    print(f\"\\nMemuat data dari: {csv_path}\")\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"File tidak ditemukan: {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    if 'text' not in df.columns or 'intent' not in df.columns:\n",
        "        raise ValueError(\"Kolom 'text' dan 'intent' harus ada di CSV\")\n",
        "\n",
        "    if label_encoder is None:\n",
        "        label_encoder = LabelEncoder()\n",
        "        df['intent_encoded'] = label_encoder.fit_transform(df['intent'])\n",
        "        intent_classes = label_encoder.classes_\n",
        "        print(f\"Label encoder baru dibuat dari data {csv_path}\")\n",
        "    else:\n",
        "        df['intent_encoded'] = label_encoder.transform(df['intent'])\n",
        "        intent_classes = label_encoder.classes_\n",
        "        print(f\"Menggunakan label encoder yang sudah ada\")\n",
        "\n",
        "    if show_distribution:\n",
        "        intent_counts = df['intent'].value_counts()\n",
        "        print(\"\\nDistribusi intent:\")\n",
        "        for intent, count in intent_counts.items():\n",
        "            print(f\"  {intent}: {count}\")\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.barplot(x=intent_counts.index, y=intent_counts.values, palette=\"viridis\")\n",
        "        plt.xlabel(\"Intent\")\n",
        "        plt.ylabel(\"Jumlah Sampel\")\n",
        "        plt.title(\"Distribusi Intent\")\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.pie(intent_counts, labels=intent_counts.index, autopct='%1.1f%%', colors=sns.color_palette(\"viridis\", len(intent_counts)))\n",
        "        plt.title(\"Proporsi Intent\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    texts = df['text'].values\n",
        "    labels = df['intent_encoded'].values\n",
        "\n",
        "    return texts, labels, intent_classes, label_encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMP8y1EczkWo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title  setup model IndoBERT\n",
        "def setup_indobert_for_intent(num_labels):\n",
        "    \"\"\"Load model IndoBERT untuk klasifikasi intent\"\"\"\n",
        "\n",
        "    print(\"Memuat model IndoBERT...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"indobenchmark/indobert-base-p2\",\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "    print(\"Model berhasil dimuat\")\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title OOD\n",
        "def enhanced_calibrate_ood(model, tokenizer, val_dataloader, save_path, temperature=1.0, percentile=85, margin=0.1):\n",
        "    \"\"\"\n",
        "    Calibrate and save OOD thresholds with adjustable tolerance\n",
        "    \"\"\"\n",
        "    print(\"Calibrating threshold for OOD detection...\")\n",
        "    thresholds = calibrate_ood_detection(model, tokenizer, val_dataloader,\n",
        "                                        temperature=temperature,\n",
        "                                        percentile=percentile,\n",
        "                                        margin=margin)\n",
        "\n",
        "    print(f\"Energy threshold: {thresholds['energy_threshold']:.4f}\")\n",
        "    print(f\"MSP threshold: {thresholds['msp_threshold']:.4f}\")\n",
        "\n",
        "    # Save thresholds\n",
        "    save_ood_thresholds(thresholds, save_path)\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "def calibrate_ood_detection(model, tokenizer, dataloader, temperature=1.0, percentile=70, margin=0.1):\n",
        "    \"\"\"\n",
        "    Calibrate thresholds for OOD detection using in-distribution data\n",
        "    with Energy-based and MSP (Maximum Softmax Probability) methods\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    # For Energy method and MSP method\n",
        "    energy_scores = []\n",
        "    msp_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Calibrating OOD detection\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Energy score (higher values for OOD)\n",
        "            energy = -temperature * torch.logsumexp(logits / temperature, dim=1)\n",
        "            energy_scores.extend(energy.cpu().numpy())\n",
        "\n",
        "            # MSP score (lower values for OOD)\n",
        "            softmax_probs = F.softmax(logits, dim=1)\n",
        "            max_probs, _ = torch.max(softmax_probs, dim=1)\n",
        "            msp_scores.extend(max_probs.cpu().numpy())\n",
        "\n",
        "    # Calculate threshold for Energy with margin (make more tolerant)\n",
        "    base_energy_threshold = np.percentile(energy_scores, percentile)\n",
        "    # Apply margin to make more tolerant (increase threshold)\n",
        "    energy_threshold = base_energy_threshold * (1 + margin)\n",
        "\n",
        "    # Calculate threshold for MSP with margin\n",
        "    base_msp_threshold = np.percentile(msp_scores, 100 - percentile)\n",
        "    # Apply margin to make more tolerant (decrease threshold)\n",
        "    msp_threshold = base_msp_threshold * (1 - margin)\n",
        "\n",
        "    return {\n",
        "        \"energy_threshold\": float(energy_threshold),\n",
        "        \"msp_threshold\": float(msp_threshold)\n",
        "    }\n",
        "\n",
        "def predict_with_ood_detection(model, tokenizer, text, thresholds, temperature=1.0, tolerance_factor=1.0):\n",
        "    \"\"\"\n",
        "    Predict with adjustable OOD detection tolerance\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    # Apply the tolerance factor to thresholds\n",
        "    energy_threshold = thresholds[\"energy_threshold\"] * tolerance_factor\n",
        "    msp_threshold = thresholds[\"msp_threshold\"] / tolerance_factor if thresholds[\"msp_threshold\"] else None\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Energy score\n",
        "        energy = -temperature * torch.logsumexp(logits / temperature, dim=1)\n",
        "        energy_score = energy.item()\n",
        "\n",
        "        # MSP score\n",
        "        softmax_probs = F.softmax(logits, dim=1)\n",
        "        max_probs, predicted_class = torch.max(softmax_probs, dim=1)\n",
        "        msp_score = max_probs.item()\n",
        "\n",
        "        # OOD detection\n",
        "        is_ood_energy = energy_score > energy_threshold\n",
        "        is_ood_msp = msp_score < msp_threshold if msp_threshold else False\n",
        "\n",
        "        # Combined OOD detection (can adjust this logic for tolerance)\n",
        "        is_ood = is_ood_energy  # You can use different combinations\n",
        "\n",
        "        return {\n",
        "            \"prediction\": predicted_class.item(),\n",
        "            \"confidence\": msp_score,\n",
        "            \"energy_score\": energy_score,\n",
        "            \"is_ood\": is_ood,\n",
        "            \"is_ood_energy\": is_ood_energy,\n",
        "            \"is_ood_msp\": is_ood_msp\n",
        "        }\n",
        "\n",
        "def save_ood_thresholds(thresholds, save_path):\n",
        "    \"\"\"\n",
        "    Save OOD thresholds to JSON file\n",
        "    \"\"\"\n",
        "    threshold_file = os.path.join(save_path, \"ood_thresholds.json\")\n",
        "    with open(threshold_file, 'w') as f:\n",
        "        json.dump(thresholds, f, indent=4)\n",
        "    print(f\"OOD thresholds saved at {threshold_file}\")\n",
        "    return threshold_file\n",
        "\n",
        "def load_ood_thresholds(model_path):\n",
        "    \"\"\"\n",
        "    Load OOD thresholds from JSON file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(os.path.join(model_path, \"ood_thresholds.json\"), 'r') as f:\n",
        "            thresholds = json.load(f)\n",
        "            return thresholds\n",
        "    except FileNotFoundError:\n",
        "        try:\n",
        "            with open(os.path.join(model_path, \"ood_threshold.json\"), 'r') as f:\n",
        "                threshold_data = json.load(f)\n",
        "                return {\n",
        "                    \"energy_threshold\": threshold_data[\"energy_threshold\"],\n",
        "                    \"msp_threshold\": None\n",
        "                }\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: OOD threshold files not found. Using default thresholds.\")\n",
        "            return {\n",
        "                \"energy_threshold\": 0.0,\n",
        "                \"msp_threshold\": 0.5\n",
        "            }"
      ],
      "metadata": {
        "id": "APTL6Ht96u9Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Focal LOSS\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n"
      ],
      "metadata": {
        "id": "VFbqGGCtvhG5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNCPJ3uFzp2V",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training function\n",
        "\n",
        "def train_intent_classifier(model, tokenizer, train_texts, train_labels, val_texts, val_labels,\n",
        "                           batch_size=16, epochs=10, learning_rate=2e-5, weight_decay=0.01,\n",
        "                           save_path=MODEL_SAVE_PATH, use_class_weights=True, patience=3, class_names=None):\n",
        "    \"\"\"\n",
        "    Melatih model IndoBERT untuk klasifikasi intent dengan perbaikan:\n",
        "    - Enhanced visualization (interactive and static)\n",
        "    - Per-class metric tracking\n",
        "    - Confusion matrix generation\n",
        "    - Batch-level metric tracking\n",
        "    - Learning rate visualization\n",
        "    \"\"\"\n",
        "\n",
        "    # Persiapkan dataset\n",
        "    print(\"Menyiapkan dataset...\")\n",
        "    train_dataset = IntentDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Compute class weights if needed\n",
        "    class_weights = None\n",
        "    if use_class_weights:\n",
        "        unique_classes = np.unique(train_labels)\n",
        "        weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_classes,\n",
        "            y=train_labels\n",
        "        )\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        class_weights = torch.FloatTensor(weights).to(device)\n",
        "        print(f\"Menggunakan class weights: {weights}\")\n",
        "\n",
        "    # Optimizer dengan weight decay untuk regularisasi\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Scheduler dengan warmup\n",
        "    num_training_steps = len(train_dataloader) * epochs\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
        "    scheduler = get_scheduler(\"cosine\", optimizer=optimizer,\n",
        "                             num_warmup_steps=num_warmup_steps,\n",
        "                             num_training_steps=num_training_steps)\n",
        "\n",
        "    # Cek untuk GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Menggunakan device: {device}\")\n",
        "    model.to(device)\n",
        "    print(f\"Mulai pelatihan model...\")\n",
        "    print(f\"Total epoch: {epochs}, batch size: {batch_size}, learning rate: {learning_rate}, weight decay: {weight_decay}\")\n",
        "\n",
        "    # Create loss function with class weights if needed\n",
        "    # Create Focal Loss with class weights\n",
        "    loss_fn = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "    print(\"Menggunakan Focal Loss dengan gamma=2.0\")\n",
        "\n",
        "    # Initialize training history\n",
        "    history = initialize_training_history()\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0  # Counter for early stopping\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        train_loss = run_training_epoch(model, device, train_dataloader, optimizer,\n",
        "                                        scheduler, loss_fn, epoch, epochs, history)\n",
        "        history['train_loss'].append(train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = run_validation_epoch(model, device, val_dataloader, loss_fn, epoch, epochs)\n",
        "        update_history_with_validation_metrics(history, val_metrics)\n",
        "\n",
        "        # Update per-class metrics if class names are provided\n",
        "        if class_names is not None:\n",
        "            update_per_class_metrics(history, val_metrics['all_labels'], val_metrics['all_preds'])\n",
        "\n",
        "            # Generate confusion matrix for this epoch\n",
        "            plot_confusion_matrix(val_metrics['all_labels'], val_metrics['all_preds'], class_names, epoch, save_path)\n",
        "\n",
        "        # Print detailed metrics\n",
        "        print_epoch_metrics(epoch, epochs, train_loss, val_metrics)\n",
        "\n",
        "        # Early stopping and model saving logic\n",
        "        counter = handle_early_stopping(model, tokenizer, val_metrics['avg_val_loss'],\n",
        "                                      best_val_loss, counter, patience,\n",
        "                                      save_path, val_metrics['all_labels'],\n",
        "                                      val_metrics['all_preds'])\n",
        "\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping triggered setelah {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "        # Update best validation loss if improved\n",
        "        if val_metrics['avg_val_loss'] < best_val_loss:\n",
        "            best_val_loss = val_metrics['avg_val_loss']\n",
        "\n",
        "    print(f\"Pelatihan selesai! Model terbaik disimpan di {save_path}\")\n",
        "\n",
        "    # Generate enhanced visualizations\n",
        "    enhanced_plot_training_results(history, save_path, class_names=class_names)\n",
        "\n",
        "    # Simpan history ke file JSON\n",
        "    save_enhanced_history(history, save_path)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def initialize_training_history():\n",
        "    \"\"\"Initialize the training history dictionary with all required keys\"\"\"\n",
        "    return {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': [],\n",
        "        'val_f1': [],\n",
        "        'val_precision': [],\n",
        "        'val_recall': [],\n",
        "        'batch_metrics': {\n",
        "            'iteration': [],\n",
        "            'loss': [],\n",
        "            'epoch': [],\n",
        "            'progress': [],\n",
        "            'learning_rates': []\n",
        "        },\n",
        "        'class_f1': [],  # Per-class F1 scores\n",
        "        'class_precision': [],  # Per-class precision\n",
        "        'class_recall': []  # Per-class recall\n",
        "    }\n",
        "\n",
        "def run_training_epoch(model, device, train_dataloader, optimizer, scheduler, loss_fn, epoch, epochs, history):\n",
        "    \"\"\"Run a single training epoch and return average loss\"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs} - Training dimulai...\")\n",
        "    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader),\n",
        "                      desc=f\"Epoch {epoch+1}/{epochs} [Training]\", leave=False)\n",
        "\n",
        "    for batch_idx, batch in progress_bar:\n",
        "        try:\n",
        "            # Pindahkan batch ke device\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass with custom loss function\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Track batch-level metrics\n",
        "            update_batch_metrics(history, batch_idx, loss.item(), epoch, len(train_dataloader), optimizer)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e):\n",
        "                print(\"Peringatan: Kehabisan memori! Membersihkan cache...\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    return train_loss / len(train_dataloader)\n",
        "\n",
        "def update_batch_metrics(history, batch_idx, loss_item, epoch, iterations_per_epoch, optimizer):\n",
        "    \"\"\"Update history with batch-level metrics\"\"\"\n",
        "    global_iteration = epoch * iterations_per_epoch + batch_idx\n",
        "    progress = (epoch + (batch_idx / iterations_per_epoch)) * 100\n",
        "\n",
        "    history['batch_metrics']['iteration'].append(global_iteration)\n",
        "    history['batch_metrics']['loss'].append(loss_item)\n",
        "    history['batch_metrics']['epoch'].append(epoch)\n",
        "    history['batch_metrics']['progress'].append(progress)\n",
        "    history['batch_metrics']['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "def run_validation_epoch(model, device, val_dataloader, loss_fn, epoch, epochs):\n",
        "    \"\"\"Run a single validation epoch and return metrics\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Validasi dimulai...\")\n",
        "    progress_bar = tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Collect predictions and labels for metrics\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'avg_val_loss': avg_val_loss,\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'all_preds': all_preds,\n",
        "        'all_labels': all_labels\n",
        "    }\n",
        "\n",
        "def update_history_with_validation_metrics(history, val_metrics):\n",
        "    \"\"\"Update history with validation metrics\"\"\"\n",
        "    history['val_loss'].append(val_metrics['avg_val_loss'])\n",
        "    history['val_accuracy'].append(val_metrics['accuracy'])\n",
        "    history['val_f1'].append(val_metrics['f1'])\n",
        "    history['val_precision'].append(val_metrics['precision'])\n",
        "    history['val_recall'].append(val_metrics['recall'])\n",
        "\n",
        "def update_per_class_metrics(history, all_labels, all_preds):\n",
        "    \"\"\"Update per-class metrics in history\"\"\"\n",
        "    class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "    class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "    class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "\n",
        "    history['class_f1'].append(class_f1.tolist())\n",
        "    history['class_precision'].append(class_precision.tolist())\n",
        "    history['class_recall'].append(class_recall.tolist())\n",
        "\n",
        "def print_epoch_metrics(epoch, epochs, avg_train_loss, val_metrics):\n",
        "    \"\"\"Print detailed metrics for an epoch\"\"\"\n",
        "    print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Val Loss: {val_metrics['avg_val_loss']:.4f}, Val Accuracy: {val_metrics['accuracy']*100:.2f}%\")\n",
        "    print(f\"  Val F1: {val_metrics['f1']:.4f}, Val Precision: {val_metrics['precision']:.4f}, Val Recall: {val_metrics['recall']:.4f}\")\n",
        "    if 'all_labels' in val_metrics and 'all_preds' in val_metrics:\n",
        "        print(f\"\\nClass-wise precision/recall/F1 setelah epoch {epoch+1}:\")\n",
        "        print(classification_report(val_metrics['all_labels'], val_metrics['all_preds'], digits=4))\n",
        "def handle_early_stopping(model, tokenizer, avg_val_loss, best_val_loss, counter, patience, save_path, all_labels, all_preds):\n",
        "    \"\"\"Handle early stopping logic and model saving\"\"\"\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        counter = 0  # Reset early stopping counter\n",
        "\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        print(f\"Menyimpan model terbaik ke {save_path}\")\n",
        "        model.save_pretrained(save_path)\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "\n",
        "        # Save classification report for best model\n",
        "        report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "        with open(os.path.join(save_path, \"classification_report.json\"), 'w') as f:\n",
        "            json.dump(report, f, indent=4)\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"Validation loss tidak membaik. Early stopping counter: {counter}/{patience}\")\n",
        "\n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWFt6WSazwgT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Evaluation\n",
        "def evaluate_model_enhanced(model, tokenizer, val_texts, val_labels, intent_classes, save_path):\n",
        "    \"\"\"Enhanced model evaluation with better visualizations\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare dataset and dataloader\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Evaluation loop\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_dataloader, desc=\"Evaluasi Model\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                 target_names=intent_classes,\n",
        "                                 output_dict=True)\n",
        "\n",
        "    # Create dataframe for visualization\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df = report_df.round(3)\n",
        "\n",
        "    # Filter for class metrics only (exclude summary rows)\n",
        "    class_df = report_df.loc[intent_classes]\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "\n",
        "    # Save classification metrics as CSV\n",
        "    report_df.to_csv(os.path.join(save_path, \"classification_report.csv\"))\n",
        "\n",
        "    # Create visualizations\n",
        "    create_static_visualizations(cm, class_df, metrics, intent_classes, save_path)\n",
        "    create_interactive_visualizations(cm, class_df, metrics, intent_classes, save_path)\n",
        "\n",
        "    # Print report summary\n",
        "    print(\"\\nModel Evaluation Report:\")\n",
        "    print(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
        "    print(f\"Macro F1-score: {report['macro avg']['f1-score']:.4f}\")\n",
        "    print(f\"Weighted F1-score: {report['weighted avg']['f1-score']:.4f}\")\n",
        "\n",
        "    return report, cm\n",
        "\n",
        "def create_static_visualizations(cm, class_df, metrics, intent_classes, save_path):\n",
        "    \"\"\"Create and save static matplotlib visualizations\"\"\"\n",
        "    # Confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "               xticklabels=intent_classes, yticklabels=intent_classes)\n",
        "    plt.title('Confusion Matrix - Final Model')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, \"final_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Classification report heatmap\n",
        "    plt.figure(figsize=(12, len(intent_classes)*0.5 + 3))\n",
        "    sns.heatmap(class_df[metrics], annot=True, cmap='YlGnBu', fmt='.3f',\n",
        "               yticklabels=intent_classes, cbar=True)\n",
        "    plt.title('Performance Metrics by Intent Class')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, \"class_performance_metrics.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def create_interactive_visualizations(cm, class_df, metrics, intent_classes, save_path):\n",
        "    \"\"\"Create and save interactive plotly visualizations\"\"\"\n",
        "    # Interactive confusion matrix\n",
        "    fig_cm = px.imshow(cm,\n",
        "                   labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Count\"),\n",
        "                   x=intent_classes, y=intent_classes,\n",
        "                   text_auto=True,\n",
        "                   color_continuous_scale='Blues')\n",
        "\n",
        "    fig_cm.update_layout(\n",
        "        title='Confusion Matrix (Interactive)',\n",
        "        width=900,\n",
        "        height=800\n",
        "    )\n",
        "    fig_cm.write_html(os.path.join(save_path, \"interactive_confusion_matrix.html\"))\n",
        "\n",
        "    # Interactive performance metrics\n",
        "    fig_perf = px.imshow(class_df[metrics],\n",
        "                   labels=dict(x=\"Metric\", y=\"Intent Class\", color=\"Score\"),\n",
        "                   x=metrics, y=intent_classes,\n",
        "                   text_auto=True,\n",
        "                   color_continuous_scale='YlGnBu')\n",
        "\n",
        "    fig_perf.update_layout(\n",
        "        title='Performance Metrics by Intent Class (Interactive)',\n",
        "        width=800,\n",
        "        height=max(400, len(intent_classes)*30)\n",
        "    )\n",
        "    fig_perf.write_html(os.path.join(save_path, \"interactive_class_performance.html\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title plot diagram\n",
        "def enhanced_plot_training_results(history, save_path, class_names=None):\n",
        "    \"\"\"\n",
        "    Enhanced function to plot training results with more detailed visualizations\n",
        "\n",
        "    Args:\n",
        "        history: Dictionary containing training history metrics\n",
        "        save_path: Path to save visualization files\n",
        "        class_names: Optional list of class names for confusion matrix\n",
        "    \"\"\"\n",
        "    # Create the static plots (same as before for compatibility)\n",
        "    static_plot_training_results(history, save_path)\n",
        "\n",
        "    # Create interactive plotly visualizations\n",
        "    interactive_plot_training_results(history, save_path)\n",
        "\n",
        "    # If we have class metrics in our history, plot those too\n",
        "    if 'class_f1' in history and class_names is not None:\n",
        "        plot_class_metrics(history, save_path, class_names)\n",
        "\n",
        "    # If we tracked learning rates, plot those\n",
        "    if 'batch_metrics' in history and 'learning_rates' in history['batch_metrics']:\n",
        "        plot_learning_rate(history, save_path)\n",
        "\n",
        "def static_plot_training_results(history, save_path):\n",
        "    \"\"\"Plot and save training metrics using matplotlib (static)\"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Plot 1: Loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Training Loss', marker='o')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "    plt.title('Loss selama Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 2: Accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy', marker='o', color='green')\n",
        "    plt.title('Akurasi selama Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 3: F1 Score\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(history['val_f1'], label='Validation F1', marker='o', color='purple')\n",
        "    plt.title('F1 Score selama Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot 4: Precision & Recall\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(history['val_precision'], label='Validation Precision', marker='o', color='orange')\n",
        "    plt.plot(history['val_recall'], label='Validation Recall', marker='o', color='brown')\n",
        "    plt.title('Precision & Recall selama Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(os.path.join(save_path, \"training_metrics.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def interactive_plot_training_results(history, save_path):\n",
        "    \"\"\"Create interactive plotly visualizations of training metrics\"\"\"\n",
        "    # Create epochs list for x-axis\n",
        "    epochs = list(range(1, len(history['train_loss']) + 1))\n",
        "\n",
        "    # Create a DataFrame for easier plotting\n",
        "    df = pd.DataFrame({\n",
        "        'Epoch': epochs,\n",
        "        'Training Loss': history['train_loss'],\n",
        "        'Validation Loss': history['val_loss'],\n",
        "        'Validation Accuracy': history['val_accuracy'],\n",
        "        'Validation F1': history['val_f1'],\n",
        "        'Validation Precision': history['val_precision'],\n",
        "        'Validation Recall': history['val_recall']\n",
        "    })\n",
        "\n",
        "    # Create subplot figure\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=('Loss', 'Accuracy', 'F1 Score', 'Precision & Recall'),\n",
        "        vertical_spacing=0.15,\n",
        "        horizontal_spacing=0.1\n",
        "    )\n",
        "\n",
        "    # Add traces for each metric\n",
        "    # Loss plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['train_loss'], mode='lines+markers', name='Training Loss'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['val_loss'], mode='lines+markers', name='Validation Loss'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Accuracy plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['val_accuracy'], mode='lines+markers', name='Validation Accuracy', line=dict(color='green')),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # F1 Score plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['val_f1'], mode='lines+markers', name='Validation F1', line=dict(color='purple')),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Precision & Recall plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['val_precision'], mode='lines+markers', name='Validation Precision', line=dict(color='orange')),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=history['val_recall'], mode='lines+markers', name='Validation Recall', line=dict(color='brown')),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        width=1200,\n",
        "        title_text=\"Training Metrics (Interactive)\",\n",
        "        hovermode=\"x unified\"\n",
        "    )\n",
        "\n",
        "    # Save interactive plot as HTML\n",
        "    fig.write_html(os.path.join(save_path, \"interactive_training_metrics.html\"))\n",
        "\n",
        "    # Create a combined metrics plot for better trend comparison\n",
        "    fig_combined = px.line(\n",
        "        df,\n",
        "        x='Epoch',\n",
        "        y=['Training Loss', 'Validation Loss', 'Validation Accuracy', 'Validation F1', 'Validation Precision', 'Validation Recall'],\n",
        "        title='All Training Metrics',\n",
        "        labels={'value': 'Metric Value', 'variable': 'Metric'}\n",
        "    )\n",
        "\n",
        "    fig_combined.update_layout(height=600, width=1000, hovermode=\"x unified\")\n",
        "    fig_combined.write_html(os.path.join(save_path, \"combined_metrics.html\"))\n",
        "\n",
        "def plot_confusion_matrix(all_labels, all_preds, class_names, epoch, save_path):\n",
        "    \"\"\"Plot and save confusion matrix for the epoch\"\"\"\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the confusion matrix\n",
        "    cm_dir = os.path.join(save_path, \"confusion_matrices\")\n",
        "    os.makedirs(cm_dir, exist_ok=True)\n",
        "    plt.savefig(os.path.join(cm_dir, f\"cm_epoch_{epoch+1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def plot_class_metrics(history, save_path, class_names):\n",
        "    \"\"\"Plot per-class performance metrics\"\"\"\n",
        "    # Create directory for class metrics\n",
        "    os.makedirs(os.path.join(save_path, \"class_metrics\"), exist_ok=True)\n",
        "\n",
        "    # Plot F1 per class if available\n",
        "    if 'class_f1' in history:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Convert dictionary structure to usable format\n",
        "        epochs = len(history['class_f1'])\n",
        "        x_epochs = list(range(1, epochs + 1))\n",
        "\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            class_f1 = [history['class_f1'][epoch][i] for epoch in range(epochs)]\n",
        "            plt.plot(x_epochs, class_f1, marker='o', label=f'{class_name}')\n",
        "\n",
        "        plt.title('F1 Score per Class')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('F1 Score')\n",
        "        plt.grid(True)\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_path, \"class_metrics\", \"f1_per_class.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Interactive version with plotly\n",
        "        fig = go.Figure()\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            class_f1 = [history['class_f1'][epoch][i] for epoch in range(epochs)]\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=x_epochs,\n",
        "                y=class_f1,\n",
        "                mode='lines+markers',\n",
        "                name=class_name\n",
        "            ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='F1 Score per Class (Interactive)',\n",
        "            xaxis_title='Epoch',\n",
        "            yaxis_title='F1 Score',\n",
        "            height=600,\n",
        "            width=1000,\n",
        "            hovermode=\"x unified\"\n",
        "        )\n",
        "        fig.write_html(os.path.join(save_path, \"class_metrics\", \"f1_per_class.html\"))\n",
        "\n",
        "def plot_learning_rate(history, save_path):\n",
        "    \"\"\"Plot learning rate changes over training\"\"\"\n",
        "    # Extract learning rates from batch metrics\n",
        "    iterations = history['batch_metrics']['iteration']\n",
        "    learning_rates = history['batch_metrics']['learning_rates']\n",
        "    epochs = history['batch_metrics']['epoch']\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(iterations, learning_rates)\n",
        "    plt.title('Learning Rate Schedule')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, \"learning_rate_schedule.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Interactive version\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=iterations,\n",
        "        y=learning_rates,\n",
        "        mode='lines',\n",
        "        name='Learning Rate'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Learning Rate Schedule (Interactive)',\n",
        "        xaxis_title='Iteration',\n",
        "        yaxis_title='Learning Rate',\n",
        "        height=500,\n",
        "        width=900\n",
        "    )\n",
        "    fig.write_html(os.path.join(save_path, \"learning_rate_schedule.html\"))\n",
        "\n",
        "def save_enhanced_history(history, save_path):\n",
        "    \"\"\"Save enhanced training history with additional visualizations\"\"\"\n",
        "    # Convert numpy arrays to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "\n",
        "    for key, value in history.items():\n",
        "        if isinstance(value, dict):\n",
        "            processed_history[key] = {}\n",
        "            for subkey, subvalue in value.items():\n",
        "                processed_history[key][subkey] = convert_to_serializable(subvalue)\n",
        "        else:\n",
        "            processed_history[key] = convert_to_serializable(value)\n",
        "\n",
        "    # Save the enhanced history\n",
        "    with open(os.path.join(save_path, \"enhanced_training_history.json\"), 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Enhanced training history saved to {os.path.join(save_path, 'enhanced_training_history.json')}\")\n",
        "\n",
        "def convert_to_serializable(value):\n",
        "    \"\"\"Convert numpy arrays and other non-serializable types to JSON-compatible types\"\"\"\n",
        "    if isinstance(value, np.ndarray):\n",
        "        return value.tolist()\n",
        "    elif isinstance(value, list):\n",
        "        if value and isinstance(value[0], np.ndarray):\n",
        "            return [item.tolist() if isinstance(item, np.ndarray) else item for item in value]\n",
        "        else:\n",
        "            return value\n",
        "    else:\n",
        "        return value"
      ],
      "metadata": {
        "id": "5y2_yA7p1I_E",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upp9G0xn0fN7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title PredictionIntent\n",
        "def predict_intent_with_enhanced_ood(text, model, tokenizer, intent_classes,\n",
        "                                     energy_threshold, msp_threshold=None,\n",
        "                                     temperature=1.0, method='combined',\n",
        "                                     label_encoder=None, device=None,\n",
        "                                     return_logits=False):\n",
        "    \"\"\"\n",
        "    Memprediksi intent dari teks input dengan deteksi Out-of-Distribution yang ditingkatkan\n",
        "\n",
        "    Args:\n",
        "        text: Teks input untuk diprediksi\n",
        "        model: Model yang sudah dilatih\n",
        "        tokenizer: Tokenizer untuk model\n",
        "        intent_classes: List nama intent\n",
        "        energy_threshold: Threshold untuk energy-based OOD detection\n",
        "        msp_threshold: Threshold untuk MSP-based OOD detection\n",
        "        temperature: Parameter temperature untuk energy\n",
        "        method: Metode deteksi OOD - 'energy', 'msp', atau 'combined'\n",
        "        label_encoder: Label encoder untuk intent classes\n",
        "        device: Device untuk inference\n",
        "        return_logits: Jika True, mengembalikan logits asli\n",
        "\n",
        "    Returns:\n",
        "        dict: Hasil prediksi dengan detail OOD detection\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if isinstance(text, str):\n",
        "        text = [text]  # Convert single text to list\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenisasi input\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # List untuk menyimpan hasil setiap input\n",
        "    results = []\n",
        "\n",
        "    # Prediksi\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Hitung energy score: -T*log(sum(exp(logits/T)))\n",
        "        energy = -temperature * torch.logsumexp(logits / temperature, dim=1)\n",
        "\n",
        "        # Hitung confidence dengan softmax\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "        predictions = torch.argmax(probabilities, dim=1)\n",
        "        max_probs = torch.max(probabilities, dim=1)[0]\n",
        "\n",
        "        for i in range(len(text)):\n",
        "            prediction = predictions[i].item()\n",
        "            energy_score = energy[i].item()\n",
        "            confidence = max_probs[i].item()\n",
        "\n",
        "            # Deteksi OOD berdasarkan metode yang dipilih\n",
        "            is_ood_energy = energy_score > energy_threshold if energy_threshold is not None else False\n",
        "            is_ood_msp = confidence < msp_threshold if msp_threshold is not None else False\n",
        "\n",
        "            if method == 'energy':\n",
        "                is_ood = is_ood_energy\n",
        "            elif method == 'msp':\n",
        "                is_ood = is_ood_msp\n",
        "            else:  # 'combined'\n",
        "                is_ood = is_ood_energy and is_ood_msp\n",
        "\n",
        "            # Tentukan intent berdasarkan hasil OOD detection\n",
        "            if is_ood:\n",
        "                predicted_intent = \"unknown\"\n",
        "                topk_intents = [(\"unknown\", 1.0)]  # Unknown intent dengan confidence 100%\n",
        "            else:\n",
        "                predicted_intent = intent_classes[prediction]\n",
        "\n",
        "                # Dapatkan top 3 intent dengan confidence tertinggi\n",
        "                top_k = min(3, len(intent_classes))\n",
        "                topk_values, topk_indices = torch.topk(probabilities[i], top_k)\n",
        "                topk_intents = [(intent_classes[idx.item()], val.item())\n",
        "                                for idx, val in zip(topk_indices, topk_values)]\n",
        "\n",
        "            # Buat hasil untuk input ini\n",
        "            result = {\n",
        "                \"text\": text[i],\n",
        "                \"intent\": predicted_intent,\n",
        "                \"confidence\": confidence,\n",
        "                \"energy_score\": energy_score,\n",
        "                \"is_ood\": is_ood,\n",
        "                \"is_ood_energy\": is_ood_energy,\n",
        "                \"is_ood_msp\": is_ood_msp if msp_threshold is not None else None,\n",
        "                \"top_intents\": topk_intents\n",
        "            }\n",
        "\n",
        "            if return_logits:\n",
        "                result[\"logits\"] = logits[i].cpu().numpy()\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "    # Jika hanya satu input, kembalikan hasil langsung tanpa list\n",
        "    if len(text) == 1:\n",
        "        return results[0]\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDr3k0Ir0rOU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run pipeline\n",
        "def run_full_pipeline_enhanced(\n",
        "    use_drive=True,\n",
        "    percentile=95,\n",
        "    ood_method='combined',\n",
        "    split_dataset=\"no\",\n",
        "    val_split=0.2,\n",
        "    batch_size=16,\n",
        "    epochs=10,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    patience=3,\n",
        "    train_csv_path=\"train.csv\",\n",
        "    val_csv_path=\"val.csv\"\n",
        "):\n",
        "    \"\"\"Jalankan pipeline lengkap dengan enhanced OOD detection dan visualisasi yang ditingkatkan\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    use_drive : bool\n",
        "        Apakah menggunakan Google Drive untuk penyimpanan\n",
        "    percentile : int\n",
        "        Persentil untuk threshold OOD detection\n",
        "    ood_method : str\n",
        "        Metode OOD detection ('msp', 'energy', 'combined')\n",
        "    split_dataset : str\n",
        "        Mode pemisahan dataset (\"yes\" untuk split dari train.csv, \"no\" untuk file terpisah)\n",
        "    val_split : float\n",
        "        Proporsi data validasi jika split_dataset=\"yes\"\n",
        "    batch_size : int\n",
        "        Ukuran batch untuk training dan evaluasi\n",
        "    epochs : int\n",
        "        Jumlah epoch training\n",
        "    learning_rate : float\n",
        "        Learning rate optimizer\n",
        "    weight_decay : float\n",
        "        Weight decay untuk regularisasi\n",
        "    patience : int\n",
        "        Early stopping patience\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    train_texts, train_labels, val_texts, val_labels, intent_classes, label_encoder = prepare_data(\n",
        "        split_dataset, val_split, train_csv_path, val_csv_path)\n",
        "\n",
        "    num_labels = len(intent_classes)\n",
        "\n",
        "    model, tokenizer = setup_indobert_for_intent(num_labels)\n",
        "\n",
        "    model, history = train_intent_classifier(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        train_texts,\n",
        "        train_labels,\n",
        "        val_texts,\n",
        "        val_labels,\n",
        "        class_names=intent_classes,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        patience=patience\n",
        "    )\n",
        "\n",
        "    thresholds = calibrate_and_evaluate(model, tokenizer, val_texts, val_labels,\n",
        "                                       intent_classes, percentile)\n",
        "\n",
        "    save_model_artifacts(model, tokenizer, intent_classes, label_encoder, history)\n",
        "\n",
        "    print_summary(num_labels, intent_classes, thresholds)\n",
        "\n",
        "    run_prediction_demo_enhanced(model, tokenizer, intent_classes, label_encoder, method=ood_method)\n",
        "\n",
        "    return model, tokenizer, intent_classes, label_encoder\n",
        "\n",
        "\n",
        "def prepare_data(split_dataset, val_split, train_csv_path=\"train.csv\", val_csv_path=\"val.csv\"):\n",
        "    \"\"\"Prepare training and validation data based on split mode\"\"\"\n",
        "\n",
        "    if split_dataset.lower() == \"yes\":\n",
        "        all_texts, all_labels, intent_classes, label_encoder = load_csv_data(train_csv_path, show_distribution=True)\n",
        "\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            all_texts, all_labels, test_size=val_split, random_state=42, stratify=all_labels\n",
        "        )\n",
        "\n",
        "        print(f\"\\n✅ Dataset telah dibagi: {len(train_texts)} data training dan {len(val_texts)} data validasi\")\n",
        "    else:\n",
        "        train_texts, train_labels, intent_classes, label_encoder = load_csv_data(train_csv_path, show_distribution=True)\n",
        "        val_texts, val_labels, _, _ = load_csv_data(val_csv_path, label_encoder=label_encoder, show_distribution=True)\n",
        "\n",
        "    return train_texts, train_labels, val_texts, val_labels, intent_classes, label_encoder\n",
        "\n",
        "\n",
        "def calibrate_and_evaluate(model, tokenizer, val_texts, val_labels, intent_classes, percentile):\n",
        "    \"\"\"Calibrate OOD detection and evaluate model\"\"\"\n",
        "    # Prepare validation dataloader for OOD calibration\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "    # Calibrate OOD detection\n",
        "    thresholds = enhanced_calibrate_ood(model, tokenizer, val_dataloader, MODEL_SAVE_PATH, percentile=percentile)\n",
        "\n",
        "    # Evaluate model and generate visualizations\n",
        "    report, cm = evaluate_model_enhanced(model, tokenizer, val_texts, val_labels, intent_classes, MODEL_SAVE_PATH)\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "\n",
        "def save_model_artifacts(model, tokenizer, intent_classes, label_encoder, history):\n",
        "    \"\"\"Save model artifacts and visualizations\"\"\"\n",
        "    # Generate enhanced visualizations for the final model\n",
        "    enhanced_plot_training_results(history, MODEL_SAVE_PATH, class_names=intent_classes)\n",
        "    save_enhanced_history(history, MODEL_SAVE_PATH)\n",
        "\n",
        "    # Save intent classes & label encoder\n",
        "    with open(f\"{MODEL_SAVE_PATH}/intent_classes.pkl\", \"wb\") as f:\n",
        "        pickle.dump(intent_classes, f)\n",
        "\n",
        "    with open(f\"{MODEL_SAVE_PATH}/label_encoder.pkl\", \"wb\") as f:\n",
        "        pickle.dump(label_encoder, f)\n",
        "\n",
        "    print(f\"\\n✅ Model telah berhasil dilatih dan disimpan di {MODEL_SAVE_PATH}\")\n",
        "\n",
        "def print_summary(num_labels, intent_classes, thresholds):\n",
        "    \"\"\"Print summary information about the trained model\"\"\"\n",
        "    print(f\"Jumlah intent: {num_labels}\")\n",
        "    print(f\"Intent yang didukung: {', '.join(intent_classes)}\")\n",
        "    print(f\"OOD detection thresholds: Energy={thresholds['energy_threshold']:.4f}, MSP={thresholds['msp_threshold']:.4f}\")\n",
        "    print(f\"Visualisasi training telah disimpan di {MODEL_SAVE_PATH}\")\n",
        "    print(f\"- Interactive plots dapat dibuka pada file HTML di folder tersebut\")\n",
        "    print(f\"- Static plots tersedia dalam format PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq-WV98s0zgH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run Prediksi\n",
        "def run_prediction_demo_enhanced(model=None, tokenizer=None, intent_classes=None, label_encoder=None, model_path=None, method='combined', test_texts=None):\n",
        "    \"\"\"Jalankan demo prediksi intent dengan model yang telah dilatih dan enhanced OOD detection\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : Model object, optional\n",
        "        Model yang sudah dilatih\n",
        "    tokenizer : Tokenizer object, optional\n",
        "        Tokenizer yang sesuai dengan model\n",
        "    intent_classes : list, optional\n",
        "        Daftar kelas intent\n",
        "    label_encoder : LabelEncoder, optional\n",
        "        Label encoder yang digunakan saat training\n",
        "    model_path : str, optional\n",
        "        Path ke model tersimpan (digunakan jika model=None)\n",
        "    method : str, optional\n",
        "        Metode OOD detection ('msp', 'energy', 'combined')\n",
        "    test_texts : list, optional\n",
        "        Daftar teks untuk diprediksi secara batch. Setelah batch, akan lanjut ke mode interaktif.\n",
        "    \"\"\"\n",
        "\n",
        "    if model_path is None:\n",
        "        model_path = MODEL_SAVE_PATH\n",
        "\n",
        "    # Jika model tidak diberikan, muat dari path penyimpanan\n",
        "    if model is None or tokenizer is None or intent_classes is None:\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Error: Model tidak ditemukan di {model_path}\")\n",
        "            print(\"Jalankan run_full_pipeline() terlebih dahulu untuk melatih model\")\n",
        "            return\n",
        "\n",
        "        # Muat model dan tokenizer\n",
        "        print(f\"Memuat model dari {model_path}...\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "        # Muat intent classes\n",
        "        import pickle\n",
        "        with open(f\"{model_path}/intent_classes.pkl\", \"rb\") as f:\n",
        "            intent_classes = pickle.load(f)\n",
        "            print(f\"Intent yang didukung: {', '.join(intent_classes)}\")\n",
        "\n",
        "    # Load OOD thresholds\n",
        "    thresholds = load_ood_thresholds(model_path)\n",
        "    energy_threshold = thresholds[\"energy_threshold\"]\n",
        "    msp_threshold = thresholds.get(\"msp_threshold\")\n",
        "\n",
        "    if msp_threshold is not None:\n",
        "        print(f\"OOD thresholds loaded: Energy={energy_threshold:.4f}, MSP={msp_threshold:.4f}\")\n",
        "    else:\n",
        "        print(f\"OOD thresholds loaded: Energy={energy_threshold:.4f}, MSP=None\")\n",
        "\n",
        "    print(f\"Menggunakan metode deteksi OOD: {method}\")\n",
        "\n",
        "    print(\"\\nDemo Prediksi Intent dengan Enhanced OOD Detection:\")\n",
        "    print(\"====================================================\")\n",
        "\n",
        "    # Helper function untuk memprediksi dan menampilkan hasil\n",
        "    def predict_and_display(text):\n",
        "        result = predict_intent_with_enhanced_ood(\n",
        "            text,\n",
        "            model,\n",
        "            tokenizer,\n",
        "            intent_classes,\n",
        "            energy_threshold,\n",
        "            msp_threshold,\n",
        "            method=method\n",
        "        )\n",
        "\n",
        "        if result[\"is_ood\"]:\n",
        "            print(f\"⚠️ Intent terdeteksi: unknown\")\n",
        "            print(f\"   Energy score: {result['energy_score']:.4f} (threshold: {energy_threshold:.4f})\")\n",
        "            if msp_threshold:\n",
        "                print(f\"   Confidence score: {result['confidence']:.4f} (threshold: {msp_threshold:.4f})\")\n",
        "        else:\n",
        "            print(f\"✓ Intent terdeteksi: {result['intent']} (confidence: {result['confidence']:.4f})\")\n",
        "\n",
        "        print(\"\\nTop 3 intent:\")\n",
        "        for i, (intent_name, score) in enumerate(result[\"top_intents\"]):\n",
        "            print(f\"  {i+1}. {intent_name}: {score:.4f}\")\n",
        "\n",
        "        print(\"\\nDetail OOD detection:\")\n",
        "        print(f\"  Energy-based: {'OOD' if result['is_ood_energy'] else 'In-Distribution'} ({result['energy_score']:.4f})\")\n",
        "        if msp_threshold:\n",
        "            print(f\"  MSP-based: {'OOD' if result['is_ood_msp'] else 'In-Distribution'} ({result['confidence']:.4f})\")\n",
        "        print(f\"  Final decision: {'OOD' if result['is_ood'] else 'In-Distribution'}\")\n",
        "\n",
        "    # Jika test_texts diberikan, lakukan prediksi batch\n",
        "    if test_texts is not None and isinstance(test_texts, list) and len(test_texts) > 0:\n",
        "        print(f\"\\nMemprediksi {len(test_texts)} contoh teks:\")\n",
        "        print(\"----------------------------\")\n",
        "\n",
        "        for i, text in enumerate(test_texts):\n",
        "            print(f\"\\nContoh #{i+1}: \\\"{text}\\\"\")\n",
        "            predict_and_display(text)\n",
        "\n",
        "        print(\"\\n----------------------------\")\n",
        "        print(\"Selesai memprediksi contoh teks. Beralih ke mode interaktif.\")\n",
        "\n",
        "    # Mode interaktif\n",
        "    print(\"\\nMode Interaktif - Masukkan teks untuk prediksi intent\")\n",
        "    print(\"Ketik 'exit' untuk keluar\")\n",
        "    print(\"----------------------------\")\n",
        "\n",
        "    # Prediksi input pengguna\n",
        "    while True:\n",
        "        user_input = input(\"\\nMasukkan teks: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        predict_and_display(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpUFrU9D-qPt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run Inference\n",
        "\n",
        "model, tokenizer, intent_classes, label_encoder = run_full_pipeline_enhanced(\n",
        "    use_drive=True,\n",
        "    percentile=90,\n",
        "    ood_method='combined',\n",
        "    split_dataset=\"yes\",\n",
        "    val_split=0.20,\n",
        "    batch_size=32,\n",
        "    epochs=12,\n",
        "    learning_rate=2.5e-5,\n",
        "    weight_decay=0.01,\n",
        "    patience=3,\n",
        "    train_csv_path=\"train.csv\",\n",
        "    val_csv_path=\"val.csv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test Set\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# ==== Step 1: Load test data ====\n",
        "test_df = pd.read_csv('tests.csv')\n",
        "test_texts = test_df['text'].tolist()\n",
        "y_true = test_df['intent'].tolist()  # Assuming the true labels column is named 'intent'\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
        "# ==== Step 2: Load label encoder and intent_classes ====\n",
        "with open(f\"{MODEL_SAVE_PATH}/label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "with open(f\"{MODEL_SAVE_PATH}/intent_classes.pkl\", \"rb\") as f: # Load intent_classes\n",
        "    intent_classes = pickle.load(f)\n",
        "\n",
        "# Encode the ground truth labels into numerical format\n",
        "y_true_encoded = label_encoder.transform(y_true)\n",
        "\n",
        "# ==== Step 3: Define prediction function ====\n",
        "def get_model_predictions(texts):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        with torch.no_grad():  # Important to avoid unnecessary gradient calculations\n",
        "            outputs = model(**inputs)\n",
        "            probs = outputs.logits.softmax(dim=1)\n",
        "            pred = probs.argmax(dim=1).item()\n",
        "            predictions.append(pred)\n",
        "    return predictions\n",
        "\n",
        "# ==== Step 4: Get predictions ====\n",
        "y_pred = get_model_predictions(test_texts)\n",
        "y_pred_labels = [intent_classes[i] for i in y_pred]\n",
        "\n",
        "# ==== Step 5: Print Classification Report ====\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_true, y_pred_labels, target_names=intent_classes))\n",
        "\n",
        "# ==== Step 6: Confusion Matrix (encoded labels for alignment) ====\n",
        "cm = confusion_matrix(y_true_encoded, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=intent_classes)\n",
        "\n",
        "# ==== Step 7: Plot Confusion Matrix ====\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "disp.plot(xticks_rotation='vertical', ax=ax, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, cmap=\"Blues\", xticklabels=intent_classes, yticklabels=intent_classes, fmt=\".2f\")\n",
        "plt.title(\"Normalized Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a list to store misclassified examples\n",
        "misclassified_examples = []\n",
        "\n",
        "for i, (true, pred_idx, text) in enumerate(zip(y_true_encoded, y_pred, test_texts)):\n",
        "    if true != pred_idx:\n",
        "        misclassified_examples.append({\n",
        "            'text': text,\n",
        "            'true_label': intent_classes[true],\n",
        "            'predicted_label': intent_classes[pred_idx]\n",
        "        })\n",
        "\n",
        "# Save misclassified examples to CSV\n",
        "if misclassified_examples:\n",
        "    misclassified_df = pd.DataFrame(misclassified_examples)\n",
        "    misclassified_csv_path = f\"{MODEL_SAVE_PATH}/misclassified_examples.csv\"\n",
        "    misclassified_df.to_csv(misclassified_csv_path, index=False)\n",
        "    print(f\"Saved {len(misclassified_examples)} misclassified examples to {misclassified_csv_path}\")\n",
        "else:\n",
        "    print(\"No misclassified examples found.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLOKcYqVT-yl",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Teks\n",
        "test_sentences = [\n",
        "    # GREETING\n",
        "    \"Halo, selamat pagi!\",\n",
        "    \"Apa kabar?\",\n",
        "    \"Hai, bot!\",\n",
        "    \"Permisi, boleh bertanya?\",\n",
        "    \"Yo, ada orang di sana?\",\n",
        "\n",
        "    # GOODBYE\n",
        "    \"Terima kasih, sampai jumpa.\",\n",
        "    \"Ok, saya pergi dulu.\",\n",
        "    \"Sampai nanti!\",\n",
        "    \"Dadah, bot.\",\n",
        "    \"Aku akan kembali nanti.\",\n",
        "\n",
        "    # CONFIRM\n",
        "    \"Iya, benar.\",\n",
        "    \"Betul sekali.\",\n",
        "    \"Ya, saya setuju.\",\n",
        "    \"Tentu saja.\",\n",
        "    \"Itu yang saya maksud.\",\n",
        "\n",
        "    # DENIED\n",
        "    \"Tidak, bukan itu.\",\n",
        "    \"Salah.\",\n",
        "    \"Bukan, maksud saya yang lain.\",\n",
        "    \"Enggak.\",\n",
        "    \"Saya tidak yakin dengan itu.\",\n",
        "\n",
        "    # AMBIGUOUS (bisa mengecoh)\n",
        "    \"Saya rasa tidak perlu, tapi ya juga boleh.\",\n",
        "    \"Mungkin... tapi entahlah.\",\n",
        "    \"Terserah kamu aja deh.\",\n",
        "    \"Boleh iya, boleh juga tidak.\",\n",
        "    \"Ya tapi tidak juga sih...\",\n",
        "    \"p\",\n",
        "    \"test\",\n",
        "    \"y\",\n",
        "    \"g\",\n",
        "    \"N\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "P9gOO73x_oxo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS_b2pfqxA8Z",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title self prediksi inference (bugged)\n",
        "# If you want to load an existing model and run predictions\n",
        "run_prediction_demo_enhanced( #model, tokenizer, intent_classes, label_encoder, method=ood_method\n",
        "    model_path=MODEL_SAVE_PATH,  # Your MODEL_SAVE_PATH\n",
        "    method='combined',  # Which OOD detection method to use\n",
        "    test_texts=test_sentences\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}