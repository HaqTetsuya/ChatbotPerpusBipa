{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMicobyL02kFPvIi/kZAml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaqTetsuya/ChatbotPerpusBipa/blob/main/IndobertPerpusChatbot_lite_cleaned_refractored.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download dependancy\n",
        "!pip install transformers torch pandas scikit-learn matplotlib seaborn tqdm deep-translator fuzzywuzzy Levenshtein"
      ],
      "metadata": {
        "id": "yEULsQMRhkgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_hbvZLvhPb3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title import dependency, load drive, and github {\"form-width\":\"20%\"}\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Transformers imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_scheduler\n",
        ")\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "!git clone https://github.com/HaqTetsuya/ChatbotPerpusBipa.git\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "FName = \"models\" #@param {type:\"string\"}\n",
        "\n",
        "# Update MODEL_SAVE_PATH with user input\n",
        "MODEL_SAVE_PATH = f\"/content/drive/MyDrive/{FName}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Dataset Class ----------#\n",
        "class IntentDataset(Dataset):\n",
        "    \"\"\"Dataset for intent classification with IndoBERT\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Convert dict of tensors to flat tensors\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CGoxF9LmjGKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Loss Function ----------#\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss implementation for handling class imbalance\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qNaLGdiRjOM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Data Loading Functions ----------#\n",
        "def load_csv_data(csv_path, label_encoder=None, show_distribution=False):\n",
        "    \"\"\"Load intent data from CSV file\"\"\"\n",
        "    print(f\"\\nLoading data from: {csv_path}\")\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"File not found: {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    if 'text' not in df.columns or 'intent' not in df.columns:\n",
        "        raise ValueError(\"Columns 'text' and 'intent' must exist in CSV\")\n",
        "\n",
        "    # Create or use existing label encoder\n",
        "    if label_encoder is None:\n",
        "        label_encoder = LabelEncoder()\n",
        "        df['intent_encoded'] = label_encoder.fit_transform(df['intent'])\n",
        "        print(f\"New label encoder created from {csv_path}\")\n",
        "    else:\n",
        "        df['intent_encoded'] = label_encoder.transform(df['intent'])\n",
        "        print(f\"Using existing label encoder\")\n",
        "\n",
        "    intent_classes = label_encoder.classes_\n",
        "\n",
        "    # Show distribution if requested\n",
        "    if show_distribution:\n",
        "        intent_counts = df['intent'].value_counts()\n",
        "        print(\"\\nIntent distribution:\")\n",
        "        for intent, count in intent_counts.items():\n",
        "            print(f\"  {intent}: {count}\")\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.barplot(x=intent_counts.index, y=intent_counts.values, palette=\"viridis\")\n",
        "        plt.xlabel(\"Intent\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.title(\"Intent Distribution\")\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.pie(intent_counts, labels=intent_counts.index, autopct='%1.1f%%',\n",
        "                colors=sns.color_palette(\"viridis\", len(intent_counts)))\n",
        "        plt.title(\"Intent Proportions\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return df['text'].values, df['intent_encoded'].values, intent_classes, label_encoder\n",
        "\n",
        "def prepare_data(split_dataset, val_split, train_csv_path=\"train.csv\", val_csv_path=\"val.csv\"):\n",
        "    \"\"\"Prepare training and validation data based on split mode\"\"\"\n",
        "    if split_dataset.lower() == \"yes\":\n",
        "        all_texts, all_labels, intent_classes, label_encoder = load_csv_data(\n",
        "            train_csv_path, show_distribution=True)\n",
        "\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            all_texts, all_labels, test_size=val_split, random_state=42, stratify=all_labels\n",
        "        )\n",
        "\n",
        "        print(f\"\\n✅ Dataset split: {len(train_texts)} training and {len(val_texts)} validation samples\")\n",
        "    else:\n",
        "        train_texts, train_labels, intent_classes, label_encoder = load_csv_data(\n",
        "            train_csv_path, show_distribution=True)\n",
        "        val_texts, val_labels, _, _ = load_csv_data(\n",
        "            val_csv_path, label_encoder=label_encoder, show_distribution=True)\n",
        "\n",
        "    return train_texts, train_labels, val_texts, val_labels, intent_classes, label_encoder"
      ],
      "metadata": {
        "id": "NHf-VdEPjTfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Model Setup ----------#\n",
        "def setup_indobert_for_intent(num_labels):\n",
        "    \"\"\"Load IndoBERT model for intent classification\"\"\"\n",
        "    print(\"Loading IndoBERT model...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"indobenchmark/indobert-base-p2\",\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "    print(\"Model loaded successfully\")\n",
        "    return model, tokenizer\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n-1lb6GijjF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Training Functions ----------#\n",
        "def train_intent_classifier(model, tokenizer, train_texts, train_labels, val_texts, val_labels,\n",
        "                          batch_size=16, epochs=10, learning_rate=2e-5, weight_decay=0.01,\n",
        "                          save_path=MODEL_SAVE_PATH, use_class_weights=True, patience=3, class_names=None):\n",
        "    \"\"\"Train intent classifier with early stopping and validation\"\"\"\n",
        "    # Create dataset and dataloaders\n",
        "    train_dataset = IntentDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Setup device, optimizer, scheduler, and loss function\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Compute class weights if needed\n",
        "    class_weights = None\n",
        "    if use_class_weights:\n",
        "        unique_classes = np.unique(train_labels)\n",
        "        weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_classes,\n",
        "            y=train_labels\n",
        "        )\n",
        "        class_weights = torch.FloatTensor(weights).to(device)\n",
        "        print(f\"Using class weights: {weights}\")\n",
        "\n",
        "    # Create optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Create scheduler with warmup\n",
        "    num_training_steps = len(train_dataloader) * epochs\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
        "    scheduler = get_scheduler(\"cosine\", optimizer=optimizer,\n",
        "                             num_warmup_steps=num_warmup_steps,\n",
        "                             num_training_steps=num_training_steps)\n",
        "\n",
        "    # Create loss function\n",
        "    loss_fn = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "    print(\"Using Focal Loss with gamma=2.0\")\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': [],\n",
        "        'val_f1': [],\n",
        "        'val_precision': [],\n",
        "        'val_recall': [],\n",
        "        'batch_metrics': {\n",
        "            'iteration': [],\n",
        "            'loss': [],\n",
        "            'epoch': [],\n",
        "            'progress': [],\n",
        "            'learning_rates': []\n",
        "        },\n",
        "        'class_f1': [],\n",
        "        'class_precision': [],\n",
        "        'class_recall': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0  # Counter for early stopping\n",
        "\n",
        "    print(f\"Starting training: {epochs} epochs, batch size: {batch_size}, LR: {learning_rate}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader),\n",
        "                          desc=f\"Epoch {epoch+1}/{epochs} [Training]\", leave=False)\n",
        "\n",
        "        for batch_idx, batch in progress_bar:\n",
        "            try:\n",
        "                # Move batch to device\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                # Forward and backward pass\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(**inputs)\n",
        "                loss = loss_fn(outputs.logits, labels)\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Update metrics\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                # Track batch metrics\n",
        "                global_iteration = epoch * len(train_dataloader) + batch_idx\n",
        "                progress = (epoch + (batch_idx / len(train_dataloader))) * 100\n",
        "\n",
        "                history['batch_metrics']['iteration'].append(global_iteration)\n",
        "                history['batch_metrics']['loss'].append(loss.item())\n",
        "                history['batch_metrics']['epoch'].append(epoch)\n",
        "                history['batch_metrics']['progress'].append(progress)\n",
        "                history['batch_metrics']['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e):\n",
        "                    print(\"Warning: Out of memory! Clearing cache...\")\n",
        "                    torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = train_loss / len(train_dataloader)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = validate_model(model, device, val_dataloader, loss_fn, epoch, epochs)\n",
        "\n",
        "        # Update history with validation metrics\n",
        "        history['val_loss'].append(val_metrics['avg_val_loss'])\n",
        "        history['val_accuracy'].append(val_metrics['accuracy'])\n",
        "        history['val_f1'].append(val_metrics['f1'])\n",
        "        history['val_precision'].append(val_metrics['precision'])\n",
        "        history['val_recall'].append(val_metrics['recall'])\n",
        "\n",
        "        # Update per-class metrics if class names are provided\n",
        "        if class_names is not None:\n",
        "            class_f1 = f1_score(val_metrics['all_labels'], val_metrics['all_preds'],\n",
        "                               average=None, zero_division=0)\n",
        "            class_precision = precision_score(val_metrics['all_labels'], val_metrics['all_preds'],\n",
        "                                           average=None, zero_division=0)\n",
        "            class_recall = recall_score(val_metrics['all_labels'], val_metrics['all_preds'],\n",
        "                                     average=None, zero_division=0)\n",
        "\n",
        "            history['class_f1'].append(class_f1.tolist())\n",
        "            history['class_precision'].append(class_precision.tolist())\n",
        "            history['class_recall'].append(class_recall.tolist())\n",
        "\n",
        "            # Generate confusion matrix for this epoch\n",
        "            plot_confusion_matrix(val_metrics['all_labels'], val_metrics['all_preds'],\n",
        "                                class_names, epoch, save_path)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Val Loss: {val_metrics['avg_val_loss']:.4f}, Val Accuracy: {val_metrics['accuracy']*100:.2f}%\")\n",
        "        print(f\"  Val F1: {val_metrics['f1']:.4f}, Val Precision: {val_metrics['precision']:.4f}, Val Recall: {val_metrics['recall']:.4f}\")\n",
        "\n",
        "        if 'all_labels' in val_metrics and 'all_preds' in val_metrics:\n",
        "            print(f\"\\nClass-wise precision/recall/F1 after epoch {epoch+1}:\")\n",
        "            print(classification_report(val_metrics['all_labels'], val_metrics['all_preds'], digits=4))\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_metrics['avg_val_loss'] < best_val_loss:\n",
        "            best_val_loss = val_metrics['avg_val_loss']\n",
        "            counter = 0  # Reset counter\n",
        "\n",
        "            # Save best model\n",
        "            if not os.path.exists(save_path):\n",
        "                os.makedirs(save_path)\n",
        "\n",
        "            print(f\"Saving best model to {save_path}\")\n",
        "            model.save_pretrained(save_path)\n",
        "            tokenizer.save_pretrained(save_path)\n",
        "\n",
        "            # Save classification report\n",
        "            report = classification_report(val_metrics['all_labels'], val_metrics['all_preds'], output_dict=True)\n",
        "            with open(os.path.join(save_path, \"classification_report.json\"), 'w') as f:\n",
        "                json.dump(report, f, indent=4)\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"Validation loss not improving. Early stopping counter: {counter}/{patience}\")\n",
        "\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "\n",
        "    print(f\"Training complete! Best model saved at {save_path}\")\n",
        "\n",
        "    # Generate visualizations\n",
        "    create_training_visualizations(history, save_path, class_names)\n",
        "\n",
        "    # Save history\n",
        "    save_training_history(history, save_path)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def validate_model(model, device, dataloader, loss_fn, epoch, epochs):\n",
        "    \"\"\"Validate model on validation dataset\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Collect predictions and labels for metrics\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_val_loss = val_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'avg_val_loss': avg_val_loss,\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'all_preds': all_preds,\n",
        "        'all_labels': all_labels\n",
        "    }"
      ],
      "metadata": {
        "id": "47xrost_j6hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Visualization Functions ----------#\n",
        "def create_training_visualizations(history, save_path, class_names=None):\n",
        "    \"\"\"Create visualizations for training history\"\"\"\n",
        "    # Create directories\n",
        "    os.makedirs(os.path.join(save_path, \"class_metrics\"), exist_ok=True)\n",
        "\n",
        "    # Plot learning rate if available\n",
        "    if 'batch_metrics' in history and 'learning_rates' in history['batch_metrics']:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(history['batch_metrics']['iteration'], history['batch_metrics']['learning_rates'])\n",
        "        plt.title('Learning Rate Schedule')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_path, \"learning_rate_schedule.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    # Plot per-class F1 scores if available\n",
        "    if 'class_f1' in history and class_names is not None:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        epochs = len(history['class_f1'])\n",
        "        x_epochs = list(range(1, epochs + 1))\n",
        "\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            class_f1 = [history['class_f1'][epoch][i] for epoch in range(epochs)]\n",
        "            plt.plot(x_epochs, class_f1, marker='o', label=f'{class_name}')\n",
        "\n",
        "        plt.title('F1 Score per Class')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('F1 Score')\n",
        "        plt.grid(True)\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_path, \"class_metrics\", \"f1_per_class.png\"))\n",
        "        plt.close()\n",
        "\n",
        "def plot_confusion_matrix(all_labels, all_preds, class_names, epoch, save_path):\n",
        "    \"\"\"Plot and save confusion matrix for an epoch\"\"\"\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the confusion matrix\n",
        "    cm_dir = os.path.join(save_path, \"confusion_matrices\")\n",
        "    os.makedirs(cm_dir, exist_ok=True)\n",
        "    plt.savefig(os.path.join(cm_dir, f\"cm_epoch_{epoch+1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def save_training_history(history, save_path):\n",
        "    \"\"\"Save training history to JSON file\"\"\"\n",
        "    # Convert numpy arrays to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "\n",
        "    for key, value in history.items():\n",
        "        if isinstance(value, dict):\n",
        "            processed_history[key] = {}\n",
        "            for subkey, subvalue in value.items():\n",
        "                processed_history[key][subkey] = convert_to_serializable(subvalue)\n",
        "        else:\n",
        "            processed_history[key] = convert_to_serializable(value)\n",
        "\n",
        "    # Save history\n",
        "    with open(os.path.join(save_path, \"training_history.json\"), 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to {os.path.join(save_path, 'training_history.json')}\")\n",
        "\n",
        "def convert_to_serializable(value):\n",
        "    \"\"\"Convert numpy arrays and other non-serializable types to JSON-compatible types\"\"\"\n",
        "    if isinstance(value, np.ndarray):\n",
        "        return value.tolist()\n",
        "    elif isinstance(value, list):\n",
        "        if value and isinstance(value[0], np.ndarray):\n",
        "            return [item.tolist() if isinstance(item, np.ndarray) else item for item in value]\n",
        "        else:\n",
        "            return value\n",
        "    else:\n",
        "        return value\n"
      ],
      "metadata": {
        "id": "n6mdJd63kGAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Evaluation Functions ----------#\n",
        "def evaluate_model(model, tokenizer, val_texts, val_labels, intent_classes, save_path):\n",
        "    \"\"\"Evaluate model and generate reports\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare dataset and dataloader\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Evaluation loop\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_dataloader, desc=\"Evaluating Model\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                 target_names=intent_classes,\n",
        "                                 output_dict=True)\n",
        "\n",
        "    # Create dataframe for visualization\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df = report_df.round(3)\n",
        "\n",
        "    # Save classification metrics as CSV\n",
        "    report_df.to_csv(os.path.join(save_path, \"classification_report.csv\"))\n",
        "\n",
        "    # Create confusion matrix visualization\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "               xticklabels=intent_classes, yticklabels=intent_classes)\n",
        "    plt.title('Confusion Matrix - Final Model')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, \"final_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Create classification report heatmap\n",
        "    class_df = report_df.loc[intent_classes]\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "\n",
        "    plt.figure(figsize=(12, len(intent_classes)*0.5 + 3))\n",
        "    sns.heatmap(class_df[metrics], annot=True, cmap='YlGnBu', fmt='.3f',\n",
        "               yticklabels=intent_classes, cbar=True)\n",
        "    plt.title('Performance Metrics by Intent Class')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, \"class_performance_metrics.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Print report summary\n",
        "    print(\"\\nModel Evaluation Report:\")\n",
        "    print(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
        "    print(f\"Macro F1-score: {report['macro avg']['f1-score']:.4f}\")\n",
        "    print(f\"Weighted F1-score: {report['weighted avg']['f1-score']:.4f}\")\n",
        "\n",
        "    return report, cm"
      ],
      "metadata": {
        "id": "9J5Dt1LVoOqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- OOD Detection ----------#\n",
        "def calibrate_ood_detection(model, tokenizer, dataloader, temperature=1.0, percentile=70, margin=0.1):\n",
        "    \"\"\"Calibrate thresholds for out-of-distribution detection\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    # For Energy method and MSP method\n",
        "    energy_scores = []\n",
        "    msp_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Calibrating OOD detection\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Energy score (higher values for OOD)\n",
        "            energy = -temperature * torch.logsumexp(logits / temperature, dim=1)\n",
        "            energy_scores.extend(energy.cpu().numpy())\n",
        "\n",
        "            # MSP score (lower values for OOD)\n",
        "            softmax_probs = F.softmax(logits, dim=1)\n",
        "            max_probs, _ = torch.max(softmax_probs, dim=1)\n",
        "            msp_scores.extend(max_probs.cpu().numpy())\n",
        "\n",
        "    # Calculate thresholds with margin\n",
        "    base_energy_threshold = np.percentile(energy_scores, percentile)\n",
        "    energy_threshold = base_energy_threshold * (1 + margin)\n",
        "\n",
        "    base_msp_threshold = np.percentile(msp_scores, 100 - percentile)\n",
        "    msp_threshold = base_msp_threshold * (1 - margin)\n",
        "\n",
        "    return {\n",
        "        \"energy_threshold\": float(energy_threshold),\n",
        "        \"msp_threshold\": float(msp_threshold)\n",
        "    }\n",
        "\n",
        "def save_ood_thresholds(thresholds, save_path):\n",
        "    \"\"\"Save OOD detection thresholds to file\"\"\"\n",
        "    threshold_file = os.path.join(save_path, \"ood_thresholds.json\")\n",
        "    with open(threshold_file, 'w') as f:\n",
        "        json.dump(thresholds, f, indent=4)\n",
        "    print(f\"OOD thresholds saved at {threshold_file}\")\n",
        "    return threshold_file\n",
        "\n",
        "def load_ood_thresholds(model_path):\n",
        "    \"\"\"Load OOD detection thresholds from file\"\"\"\n",
        "    try:\n",
        "        with open(os.path.join(model_path, \"ood_thresholds.json\"), 'r') as f:\n",
        "            thresholds = json.load(f)\n",
        "            return thresholds\n",
        "    except FileNotFoundError:\n",
        "        try:\n",
        "            with open(os.path.join(model_path, \"ood_threshold.json\"), 'r') as f:\n",
        "                threshold_data = json.load(f)\n",
        "                return {\n",
        "                    \"energy_threshold\": threshold_data[\"energy_threshold\"],\n",
        "                    \"msp_threshold\": None\n",
        "                }\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: OOD threshold files not found. Using default thresholds.\")\n",
        "            return {\n",
        "                \"energy_threshold\": 0.0,\n",
        "                \"msp_threshold\": 0.5\n",
        "            }"
      ],
      "metadata": {
        "id": "WUVWQ1Ifoi90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ---------- Main Pipeline ----------#\n",
        "def run_intent_classification_pipeline(\n",
        "    use_drive=True,\n",
        "    percentile=95,\n",
        "    split_dataset=\"no\",\n",
        "    val_split=0.2,\n",
        "    batch_size=16,\n",
        "    epochs=10,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    patience=3,\n",
        "    train_csv_path=\"train.csv\",\n",
        "    val_csv_path=\"val.csv\"\n",
        "):\n",
        "    \"\"\"Run full intent classification pipeline\"\"\"\n",
        "    # Create save directory\n",
        "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    # Prepare data\n",
        "    train_texts, train_labels, val_texts, val_labels, intent_classes, label_encoder = prepare_data(\n",
        "        split_dataset, val_split, train_csv_path, val_csv_path)\n",
        "\n",
        "    num_labels = len(intent_classes)\n",
        "    print(f\"Number of intents: {num_labels}\")\n",
        "    print(f\"Supported intents: {', '.join(intent_classes)}\")\n",
        "\n",
        "    # Setup model\n",
        "    model, tokenizer = setup_indobert_for_intent(num_labels)\n",
        "\n",
        "    # Train model\n",
        "    model, history = train_intent_classifier(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        train_texts,\n",
        "        train_labels,\n",
        "        val_texts,\n",
        "        val_labels,\n",
        "        class_names=intent_classes,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        patience=patience\n",
        "    )\n",
        "\n",
        "    # Prepare validation dataloader for OOD calibration\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "    # Calibrate OOD detection\n",
        "    thresholds = calibrate_ood_detection(model, tokenizer, val_dataloader, percentile=percentile)\n",
        "    save_ood_thresholds(thresholds, MODEL_SAVE_PATH)\n",
        "    print(f\"OOD detection thresholds: Energy={thresholds['energy_threshold']:.4f}, MSP={thresholds['msp_threshold']:.4f}\")\n",
        "\n",
        "    # Evaluate model\n",
        "    report, cm = evaluate_model(model, tokenizer, val_texts, val_labels, intent_classes, MODEL_SAVE_PATH)\n",
        "\n",
        "    # Save intent classes & label encoder\n",
        "    with open(f\"{MODEL_SAVE_PATH}/intent_classes.pkl\", \"wb\") as f:\n",
        "        pickle.dump(intent_classes, f)\n",
        "\n",
        "    with open(f\"{MODEL_SAVE_PATH}/label_encoder.pkl\", \"wb\") as f:\n",
        "        pickle.dump(label_encoder, f)\n",
        "\n",
        "    print(f\"\\n✅ Model successfully trained and saved at {MODEL_SAVE_PATH}\")\n",
        "    print(f\"Visualizations saved at {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    return model, tokenizer, intent_classes, label_encoder"
      ],
      "metadata": {
        "id": "YOEaveaXoxoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    model, tokenizer, intent_classes, label_encoder = run_intent_classification_pipeline(\n",
        "        use_drive=True,\n",
        "        percentile=90,\n",
        "        split_dataset=\"yes\",\n",
        "        val_split=0.20,\n",
        "        batch_size=32,\n",
        "        epochs=12,\n",
        "        learning_rate=2.5e-5,\n",
        "        weight_decay=0.01,\n",
        "        patience=3,\n",
        "        train_csv_path=\"train.csv\",\n",
        "\t\tval_csv_path=\"val.csv\"\n",
        "\t\t)"
      ],
      "metadata": {
        "id": "wnLYoQVio6l2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}